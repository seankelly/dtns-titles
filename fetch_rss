#!/usr/bin/env python3

import argparse
import json
import os.path
import re

from dateutil import parser
from lxml import etree
import requests

DTNS_RSS_URL = 'https://feeds.feedburner.com/DailyTechNewsShow'


class ShowFeed:

    def __init__(self, show_name, feed_url, post_link=False):
        self.show_name = show_name
        self.feed_url = feed_url
        # Should the episode link to the audio or the post that will contain a
        # link to the audio? Episodes that require authorization will need to
        # link to the post to use the right, unexpired auth.
        self.post_link = post_link
        self.show_number = re.compile(r'{} (\d+)'.format(show_name))
        self.episodes = []

    def load_feed(self):
        """Parse all episodes found in the feed."""
        feed_req = requests.get(self.feed_url)
        feed_tree = etree.fromstring(feed_req.content)
        episodes = []
        feed_episodes = feed_tree.xpath('//item')
        for episode in feed_episodes:
            raw_title_el = episode.find('title')
            raw_title = raw_title_el.text
            show_title = self._extract_title(raw_title)
            if show_title:
                episode_number, title = show_title
            else:
                # Skip unknown episodes. This is run in a cron so minimize output.
                continue
            pub_date = episode.find('pubDate')
            air_date = parser.parse(pub_date.text)
            if not self.post_link:
                enclosure = episode.find('enclosure')
                download_link = enclosure.get('url')
            else:
                link = episode.find('link')
                download_link = link.text
            episodes.append({
                'number': episode_number,
                'title': title,
                'date': air_date.strftime('%Y-%m-%d'),
                'download': download_link,
            })
        self.episodes = episodes

    def load_csv(self, show_csv_file):
        with open(show_csv_file) as show_csv:
            shows = csv.reader(show_csv)
            for show in shows:
                raw_title, pub_date, patreon_show_url = show
                show_title = self._extract_title(raw_title)
                if show_title:
                    episode_number, title = show_title
                else:
                    continue
                post_link = PATREON_URL + patreon_show_url
                air_date = parser.parse(pub_date)
                self.episodes.append({
                    'number': episode_number,
                    'title': title,
                    'date': air_date.strftime('%Y-%m-%d'),
                    'download': post_link,
                })


    def add_new_shows(self, show_key, all_shows):
        def sort_shows(episode):
            return episode['number']

        if show_key not in all_shows:
            all_shows[show_key] = []
        show_episodes = all_shows[show_key]
        known_episodes = {episode['number']: episode['date']
                          for episode in show_episodes}
        new_episodes = []
        updated_episodes = {}
        for feed_episode in self.episodes:
            episode_number = feed_episode['number']
            if episode_number not in known_episodes:
                new_episodes.append(feed_episode)
                known_episodes[episode_number] = feed_episode['date']
            elif known_episodes[episode_number] < feed_episode['date']:
                if episode_number not in updated_episodes or \
                   updated_episodes[episode_number]['date'] < feed_episode['date']:
                    updated_episodes[episode_number] = feed_episode
        new_episodes.sort(key=sort_shows)
        if new_episodes:
            for new_episode in new_episodes:
                print("Adding new %s episode %d - %s" % (
                    self.show_name, new_episode['number'], new_episode['title']))
            show_episodes.extend(new_episodes)
        if updated_episodes:
            for idx, episode in enumerate(show_episodes):
                if episode['number'] in updated_episodes:
                    updated_episode = updated_episodes[episode['number']]
                    print("Updating %s episode %d - %s" % (
                        self.show_name, updated_episode['number'], updated_episode['title']))
                    show_episodes[idx] = updated_episode
            show_episodes.sort(key=sort_shows)
        return bool(new_episodes) or bool(updated_episodes)

    def _extract_title(self, raw_title):
        """Extract the episode number and title from the full title."""
        episode_match = self.show_number.search(raw_title)
        if episode_match:
            episode_number = int(episode_match.group(1))
            start = episode_match.start()
            end = episode_match.end()
            raw_title = raw_title[0:start] + raw_title[end:]
            title = raw_title.strip(' -â€“')
            return episode_number, title


def main():
    parser = argparse.ArgumentParser(description="Fetch new DTNS or GDI titles")
    parser.add_argument('--output', default='titles.json',
                        help="Output file for the titles.")
    parser.add_argument('--patreon-rss',
                        help="Patreon RSS feed")
    args = parser.parse_args()

    if os.path.exists(args.output):
        with open(args.output, 'r') as input:
            episodes = json.load(input)
    else:
        episodes = {}

    # Search DTNS first.
    dtns = ShowFeed('DTNS', DTNS_RSS_URL)
    dtns.load_feed()
    new_dtns = dtns.add_new_shows('dailytechnewsshow', episodes)
    # Support loading GDI episodes if a Patreon RSS feed is given. It is
    # assumed it only contains GDI episodes.
    new_gdi = False
    if args.patreon_rss:
        gdi = ShowFeed('GDI', args.patreon_rss, post_link=True)
        gdi.load_feed()
        new_gdi = gdi.add_new_shows('gooddayinternet', episodes)

    if new_dtns or new_gdi:
        with open(args.output, 'w') as output:
            json.dump(episodes, output)


if __name__ == '__main__':
    main()
